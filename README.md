# diabetes_prediction_model
Logistic regression is employed to analyze and predict the onset of Type 2 diabetes in women, utilizing a dataset encompassing key health metrics like glucose levels and BMI. The analysis demonstrates the application of data manipulation, statistical methods, and model evaluation techniques in a real-world healthcare context.


Project Description
This project focuses on applying logistic regression to predict the onset of Type 2 diabetes in women. The data set includes various health metrics, like glucose levels, blood pressure, body mass index, and family history, among others. This analysis is crucial for early detection and management of diabetes.

Technical Skills Showcased
Data Manipulation: Utilized pandas for data cleaning and preparation.
Statistical Analysis: Performed exploratory data analysis (EDA) using seaborn and matplotlib, including correlation matrices and boxplots.
Model Building: Applied logistic regression using sklearn and statsmodels, and conducted feature selection using ExhaustiveFeature Selector.
Model Evaluation: Utilized various metrics like confusion matrix, ROC curve, and AUC score for model validation.
Programming Best Practices: Adhered to code modularity, readability, and efficient data handling.

Data
The dataset Diabetes.txt contains health metrics of 392 women at risk for diabetes. Key variables include glucose levels, blood pressure, BMI, family diabetes history, etc.

Results and Findings
Model Insights: The logistic regression model identifies key predictors for diabetes in women.
Accuracy: Achieved an accuracy of 72%, indicating moderate predictive power.
Statistical Significance: Variables like glucose level and BMI showed significant predictive ability.
Conclusions
The model demonstrates the potential of logistic regression in medical predictions.
Certain predictors like glucose and BMI are critical in diabetes prediction.
Further refinement is needed to improve model accuracy for clinical application.
Future Work
Integrate more diverse datasets to improve model robustness.
Explore other machine learning algorithms for comparison.
Implement feature engineering to uncover more insights.
